{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAU 2023/2024\n",
    "## **Autori:** Laura Fulajtárová (50%), Bruno Kristián (50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fáza 3 - Strojové učenie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from IPython.display import Image\n",
    "import copy\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneR algoritmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dočasne sme spojili dáta z trénovacej a testovacej množiny, aby sme mohli vytvoriť OneR model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\", sep = ',')\n",
    "y_train = pd.read_csv(\"y_train.csv\", sep = ',')\n",
    "X_test = pd.read_csv(\"X_test.csv\", sep = ',')\n",
    "y_test = pd.read_csv(\"y_test.csv\", sep = ',')\n",
    "\n",
    "merged_train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data = merged_train_data\n",
    "\n",
    "merged_test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data = merged_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Rule algoritmus sme naprogramovali iba pre číselné hodnoty, pretože v dátach sme si v minulých fázach premenili pomocou encodingu všetky kategorické hodnoty na číselné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_rule_algorithm(data, target_variable, explored_columns):\n",
    "    best_feature = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for feature in data.columns:\n",
    "        if feature == target_variable or feature in explored_columns:\n",
    "            continue\n",
    "        \n",
    "        mean_values = data.groupby(target_variable)[feature].mean()\n",
    "        split_point = mean_values.mean()\n",
    "        \n",
    "        temp_data = data.copy()\n",
    "        temp_data['prediction'] = temp_data[feature] > split_point\n",
    "        \n",
    "        accuracy = accuracy_score(temp_data[target_variable], temp_data['prediction'])\n",
    "        precision = precision_score(temp_data[target_variable], temp_data['prediction'])\n",
    "        recall = recall_score(temp_data[target_variable], temp_data['prediction'])\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_feature = feature\n",
    "            best_accuracy = accuracy\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "            result = temp_data['prediction']\n",
    "    \n",
    "    return best_feature, best_accuracy, best_precision, best_recall, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spustíme algoritmus OneR s predikovanou premennou \"ack\" a vyhodnotíme metriky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na vyhodnotenie modelu sme použili nasledovné metriky:\n",
    "- Accuracy - ako často klasiﬁkátor správne klasifikoval \n",
    "\n",
    "- Precision - koľko správne predikovaných príkladov bolo pozitívnych\n",
    "\n",
    "- Recall - koľko pozitívnych príkladov bolo správne predikovaných"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneR s jednou premennou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'ack'\n",
    "\n",
    "oneR_train_data = copy.deepcopy(train_data)\n",
    "best_feature, best_accuracy, best_precision, best_recall, prediction = one_rule_algorithm(oneR_train_data, target_variable, [])\n",
    "print('Best column from OneR:', best_feature)\n",
    "print('Accuracy:', best_accuracy)\n",
    "print('Precision:', best_precision)\n",
    "print('Recall:', best_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že algoritmus vyhodnotil \"page_activity_duration\" ako najlepšiu premennú pre predikciu \"ack\". Algoritmus na základe premennej \"page_activity_duration\" predikoval s presnosťou takmer 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneR s viacerými premennými"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz skúsime spustiť OneR algoritmus viackrát a zistiť ktoré premenné najlepšie predikujú \"ack\".\n",
    "\n",
    "Po zistení najlepších premenných ich použijeme na vytvorenie modelu. Pri vytváraní modelu prihliadame na presnosť predikcie danej premennej. Čím vyššia presnosť, tým má vyššiu váhu pri rozhodaovaní. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'ack'\n",
    "results = []\n",
    "explored_columns = []\n",
    "final_results = []\n",
    "\n",
    "for _ in range(5):\n",
    "    oneR_train_data = copy.deepcopy(train_data)\n",
    "    best_feature, best_accuracy, best_precision, best_recall, prediction = one_rule_algorithm(oneR_train_data, target_variable, explored_columns)\n",
    "    explored_columns.append(best_feature)\n",
    "    results.append((best_accuracy, prediction.tolist()))\n",
    "\n",
    "for result in results:\n",
    "    if result[0] > 0.7:\n",
    "        final_results.append(result[1])\n",
    "        final_results.append(result[1])\n",
    "    else:\n",
    "        final_results.append(result[1])\n",
    "\n",
    "combined_predictions = [Counter(sample).most_common(1)[0][0] for sample in zip(*final_results)]\n",
    "\n",
    "overall_accuracy = accuracy_score(train_data[target_variable], combined_predictions)\n",
    "overall_precision = precision_score(train_data[target_variable], combined_predictions, zero_division=0)\n",
    "overall_recall = recall_score(train_data[target_variable], combined_predictions)\n",
    "\n",
    "table_data = {\n",
    "    \"Algorithm\": [\"OneR\"],\n",
    "    \"Accuracy\": [overall_accuracy],\n",
    "    \"Precision\": [overall_precision],\n",
    "    \"Recall\": [overall_recall]\n",
    "}\n",
    "\n",
    "oneR_table = pd.DataFrame(table_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepšie premenné k predikcií \"ack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = {\n",
    "    \"Feature\": explored_columns,\n",
    "    \"Accuracy\": [result[0] for result in results]\n",
    "}\n",
    "\n",
    "accuracy_table = pd.DataFrame(table_data)\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výsledky metrík pre predikovanie premennej \"ack\" pomocou OneR algoritmu s viacerými premennými."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overall Accuracy:', overall_accuracy)\n",
    "print('Overall Precision:', overall_precision)\n",
    "print('Overall Recall:', overall_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn Klasifikátory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stromový klasifikátor Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "table_data = {\n",
    "    \"Algorithm\": [\"Random Forest\"],\n",
    "    \"Accuracy\": [accuracy],\n",
    "    \"Precision\": [precision],\n",
    "    \"Recall\": [recall]\n",
    "}\n",
    "\n",
    "RF_table = pd.DataFrame(table_data)\n",
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "top_5_features_rf = sorted_indices[:5]\n",
    "top_5_importances = feature_importances[top_5_features_rf]\n",
    "\n",
    "feature_names = X_test.columns.values\n",
    "\n",
    "top_5_feature_names_rf = [feature_names[i] for i in top_5_features_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stromový klasifikátor Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_accuracy = accuracy_score(y_test, gb_y_pred)\n",
    "gb_precision = precision_score(y_test, gb_y_pred)\n",
    "gb_recall = recall_score(y_test, gb_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {gb_accuracy:.2f}\")\n",
    "print(f\"Precision: {gb_precision:.2f}\")\n",
    "print(f\"Recall: {gb_recall:.2f}\")\n",
    "\n",
    "table_data = {\n",
    "    \"Algorithm\": [\"Gradient Boosting\"],\n",
    "    \"Accuracy\": [gb_accuracy],\n",
    "    \"Precision\": [gb_precision],\n",
    "    \"Recall\": [gb_recall]\n",
    "}\n",
    "\n",
    "GB_table = pd.DataFrame(table_data)\n",
    "\n",
    "feature_importances = gb_model.feature_importances_\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "top_5_features_gb = sorted_indices[:5]\n",
    "top_5_importances = feature_importances[top_5_features_gb]\n",
    "feature_names = X_test.columns.values\n",
    "\n",
    "top_5_feature_names = [feature_names[i] for i in top_5_features_gb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nestromový algoritmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre nestromový algoritmus sme si vybrali KNN klasifikátor.\n",
    "\n",
    "Najskôr si dáta scalujeme a normalizujeme, aby KNN klasifikátor pracoval efektívnejšie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(X_train)\n",
    "train_data_scaled = pd.DataFrame(scaled_data, columns=X_train.columns)\n",
    "\n",
    "power = PowerTransformer(method='yeo-johnson', standardize=True) \n",
    "X_train_normalised = power.fit_transform(train_data_scaled)\n",
    "X_train_scaled_normalised = pd.DataFrame(X_train_normalised, columns=X_train.columns)\n",
    "\n",
    "scaled_test_data = scaler.transform(X_test)\n",
    "test_data_scaled = pd.DataFrame(scaled_test_data, columns=X_test.columns)\n",
    "\n",
    "normalized_test_data = power.transform(test_data_scaled)\n",
    "test_data_scaled_normalized = pd.DataFrame(normalized_test_data, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri stromových klasifikačných algoritmoch sme nemuseli použiť feature selection, pretože si s tým poradili samé. Pri nestromových algoritmoch je to však inak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'page_activity_duration', 'pct_doubleclick', 'pct_mouse_click', 'wild_mouse_duration',\n",
    "    'pct_mouse_move', 'pct_input', 'pct_click', 'session_start', \n",
    "    'scroll_move_total_rel_distance', 'pct_scroll_move'\n",
    "]\n",
    "\n",
    "X_train_filtered = X_train_scaled_normalised[columns_to_keep]\n",
    "X_test_filtered = test_data_scaled_normalized[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN klasifikátor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn_model.fit(X_train_filtered, y_train)\n",
    "\n",
    "knn_y_pred = knn_model.predict(X_test_filtered)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "knn_precision = precision_score(y_test, knn_y_pred)\n",
    "knn_recall = recall_score(y_test, knn_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {knn_accuracy:.2f}\")\n",
    "print(f\"Precision: {knn_precision:.2f}\")\n",
    "print(f\"Recall: {knn_recall:.2f}\")\n",
    "\n",
    "table_data_knn = {\n",
    "    \"Algorithm\": [\"K-Nearest Neighbors\"],\n",
    "    \"Accuracy\": [knn_accuracy],\n",
    "    \"Precision\": [knn_precision],\n",
    "    \"Recall\": [knn_recall]\n",
    "}\n",
    "\n",
    "knn_table = pd.DataFrame(table_data_knn)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "selector.fit(X_train_filtered, y_train)\n",
    "top_5_indices = selector.get_support(indices=True)\n",
    "top_5_features_knn = X_train_filtered.columns[top_5_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porovnanie výsledkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(oneR_table, RF_table, GB_table, knn_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z porovnania výsledkov vidíme, že najlepšie výsledky dosiahol Gradient Boosting klasifikátor.\n",
    "\n",
    "Náš oneR algoritmus dosiahol presnosť 83%. Dôvodom je jednoduchosť algoritmu a potreba predikovať pomocou viacerých premenných. Keďže najlepší atribút má presnosť okolo 90% a ostané atribúty majú presnosť len okolo 60%, tak pri predikovaní pomocou viacerých atribútov sa presnosť zníži.\n",
    "\n",
    "OneR algoritmus predikuje s precíznosťou 82%, čo je o viac ako 10% menej ako Gradient Boosting klasifikátor alebo Random Forest klasifikátor.\n",
    "\n",
    "Náš algoritmus je o 15% horší ako ako Gradient Boosting klasifikátor alebo Random Forest klasifikátor v predikovaní pozitívnych príkladov zo všetkých pozitívnych príkladov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One Rule Algorithm:\")\n",
    "for column in explored_columns:\n",
    "    print(column)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Random Forest:\")\n",
    "for column in top_5_feature_names_rf:\n",
    "    print(column)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Gradient Boosting:\")\n",
    "for column in top_5_feature_names:\n",
    "    print(column)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"K Nearest Neighbours:\")\n",
    "for column in top_5_features_knn:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že algoritmy sa podobajú vo výbere atribútov, ktoré najlepšie predikujú \"ack\". Najlepšie atribúty sú \"page_activity_duration\", \"pct_doubleclick\" a \"pct_click\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualizácia natrénovaných pravidiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualizujeme si Random Forest klasifikátor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_index = 0\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(clf.estimators_[tree_index], filled=True, feature_names=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
    "plt.title(f\"Decision Tree {tree_index + 1} from Random Forest Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualizácia pravidiel pre Random Forest klasifikátor na základe accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "feature_accuracies = []\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    X_train_single_feature = X_train.iloc[:, i:i+1]  # Assuming X_train is a DataFrame\n",
    "    X_test_single_feature = X_test.iloc[:, i:i+1]    # Assuming X_test is a DataFrame\n",
    "    \n",
    "    clf_single_feature = RandomForestClassifier()\n",
    "    clf_single_feature.fit(X_train_single_feature, y_train.values.ravel())  # Convert y_train to a 1D array\n",
    "    \n",
    "    predictions_single_feature = clf_single_feature.predict(X_test_single_feature)\n",
    "    \n",
    "    accuracy_single_feature = accuracy_score(y_test, predictions_single_feature)\n",
    "    feature_accuracies.append((X_train.columns[i], accuracy_single_feature))\n",
    "\n",
    "sorted_features = sorted(feature_accuracies, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_5_feature_names = [feat[0] for feat in sorted_features[:5]]\n",
    "top_5_accuracies = [feat[1] for feat in sorted_features[:5]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_5_feature_names, top_5_accuracies, color='skyblue')\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Top 5 Features with Accuracies')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vynechanie ostatnych stlpcov\n",
    "for column in X_train.columns:\n",
    "    if column not in top_5_feature_names_rf or column not in top_5_feature_names or column not in top_5_features_knn or column not in explored_columns:\n",
    "        X_train = X_train.drop(column, axis=1)\n",
    "        X_test = X_test.drop(column, axis=1)\n",
    "\n",
    "# fixnutie y_train\n",
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve pred optimalizáciou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "# Initialize and train the GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "gb_y_train_pred = gb_model.predict(X_train)\n",
    "gb_train_accuracy = accuracy_score(y_train, gb_y_train_pred)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "gb_y_test_pred = gb_model.predict(X_test)\n",
    "gb_test_accuracy = accuracy_score(y_test, gb_y_test_pred)\n",
    "\n",
    "# Learning curve calculation\n",
    "train_sizes, train_scores, test_scores = learning_curve(gb_model, X_train, y_train, cv=5, n_jobs=-1, \n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# Mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Mean and standard deviation for test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plotting the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label=\"Training score\", color=\"blue\", marker='o')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"blue\", alpha=0.15)\n",
    "\n",
    "plt.plot(train_sizes, test_mean, label=\"Test score\", color=\"green\", marker='o')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"green\", alpha=0.15)\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Data Size\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "gb_train_accuracy, gb_test_accuracy\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výsledky ukazujú, že model dosiahol presnosť 95.67% na trénovacej množine a 94.56% na testovacej množine. Tieto hodnoty sú veľmi blízke k sebe, čo naznačuje, že model má dobrú schopnosť generalizácie a nie je výrazne preučený (overfitovaný). Tento výsledok je pozitívny, pretože ukazuje, že model dobre predpovedá na dátach, na ktorých nebol trénovaný."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complexity curve pred optimalizáciou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analysis for varying model complexity\n",
    "results = []\n",
    "max_depth_range = range(1, 11)  # Varying max_depth from 1 to 10\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=depth, random_state=1)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate error on training set\n",
    "    train_pred = gb_model.predict(X_train)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    # Calculate error on test set\n",
    "    test_pred = gb_model.predict(X_test)\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    results.append({'max_depth': depth, 'train_error': train_error, 'test_error': test_error})\n",
    "\n",
    "# Convert results to a DataFrame for easier plotting\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plotting the errors vs model complexity\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['max_depth'], results_df['train_error'], label='Training Error', marker='o', color='blue')\n",
    "plt.plot(results_df['max_depth'], results_df['test_error'], label='Testing Error', marker='o', color='red')\n",
    "\n",
    "plt.title(\"Error vs. Model Complexity (Max Depth)\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "results_df\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S rastúcou hĺbkou stromu (max_depth) v Gradient Boosting modeli dochádza k poklesu chyby na trénovacej množine, avšak chyba na testovacej množine sa stabilizuje pri max_depth 7. Ďalšie zvyšovanie hĺbky stromu neprináša zlepšenie na testovacej množine, čo naznačuje optimálnu hĺbku okolo 7 a potenciálne riziko overfittingu pri vyšších hodnotách."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting je veľmi presný model, obzvlášť účinný pri práci s komplexnými dátami, čo je výhodné v rôznych aplikáciách od klasifikácie po regresiu. Jeho flexibilita umožňuje prispôsobenie rozličným typom stratových funkcií, čo ho robí vhodným pre rôzne prediktívne úlohy. Okrem toho, ponúka viacero možností na kontrolu overfittingu, ako napríklad nastavenie hĺbky stromu a rýchlosti učenia, čo zlepšuje jeho schopnosť generalizovať na nevidené dáta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vysvetlenie hyperparametrov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = GradientBoostingClassifier().get_params()\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ccp_alpha: Komplexita stromu. Čím vyššia hodnota, tým viac sa strom zjednoduší.\n",
    "- criterion: Kritérium pre výber atribútu, ktorý sa použije na rozdelenie uzla.\n",
    "- init: Inicializácia stromu.\n",
    "- learning_rate: Rýchlosť učenia.\n",
    "- loss: Funkcia straty.\n",
    "- max_depth: Maximálna hĺbka stromu.\n",
    "- max_features: Maximálny počet atribútov, ktoré sa použijú na rozdelenie uzla.\n",
    "- max_leaf_nodes: Maximálny počet listových uzlov.\n",
    "- min_impurity_decrease: Uzol sa rozdelí, ak sa impurity v jeho rodičovskom uzle zníži o túto hodnotu.\n",
    "- min_samples_leaf: Minimálny počet vzoriek v listovom uzle.\n",
    "- min_weight_fraction_leaf: Minimálna váhová frakcia v listovom uzle.\n",
    "- n_estimators: Počet stromov v ensemble.\n",
    "- n_iter_no_change: Počet iterácií bez zlepšenia pred ukončením učenia.\n",
    "- random_state: Seed pre generovanie náhodných čísel.\n",
    "- subsample: Podiel vzoriek použitých na trénovanie každého stromu.\n",
    "- tol: Tolerancia pre zastavenie učenia.\n",
    "- validation_fraction: Podiel vzoriek použitých na validáciu každého stromu.\n",
    "- verbose: Výpis informácií o učení.\n",
    "- warm_start: Použiť existujúci model na trénovanie a pridať ďalšie stromy do ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingClassifier()\n",
    "\n",
    "# Define your parameter grid\n",
    "gb_parameters = {\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'loss': ['log_loss','exponential'],\n",
    "    'max_depth': [3,6,8,10],\n",
    "    'n_estimators': [100,200, 300],\n",
    "    'learning_rate': [0.09, 0.1,0.11],\n",
    "    'random_state': [None,1,2],\n",
    "    \n",
    "    }\n",
    "\n",
    "scoring = ['accuracy', 'precision_micro']\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "gb_clf = GridSearchCV(estimator=estimator, \n",
    "                   param_grid=gb_parameters,\n",
    "                   cv=5,\n",
    "                   scoring=scoring,\n",
    "                   refit='accuracy', \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "gb_search = gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Output the results\n",
    "print(gb_search.best_estimator_)\n",
    "print(gb_search.best_score_)\n",
    "print(gb_search.best_params_)\n",
    "print(gb_search.n_splits_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting before hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_accuracy = accuracy_score(y_test, gb_y_pred)\n",
    "gb_precision2 = precision_score(y_test, gb_y_pred)\n",
    "gb_recall2 = recall_score(y_test, gb_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {gb_accuracy:.5f}\")\n",
    "print(f\"Precision: {gb_precision2:.5f}\")\n",
    "print(f\"Recall: {gb_recall2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = gb_search.best_estimator_\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_accuracy = accuracy_score(y_test, gb_y_pred)\n",
    "gb_precision2 = precision_score(y_test, gb_y_pred)\n",
    "gb_recall2 = recall_score(y_test, gb_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {gb_accuracy:.5f}\")\n",
    "print(f\"Precision: {gb_precision2:.5f}\")\n",
    "print(f\"Recall: {gb_recall2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest je obľúbený pre svoju robustnosť a výkonnosť, ktorá je často porovnateľná s komplexnejšími modelmi. Vďaka svojmu spôsobu náhodnej výberu prvkov a tvorby stromov poskytuje Random Forest vynikajúcu odolnosť voči overfittingu. Táto metóda je tiež schopná efektívne spracovávať veľké dátove sady s veľkým počtom premenných, čo je výhodné pri riešení širokej škály úloh prediktívnej analýzy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vysvetlenie hyperparametrov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = RandomForestClassifier().get_params()\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bootstrap: Použiť bootstrap vzorkovanie. Bootstrap vzorkovanie je metóda, ktorá sa používa na zlepšenie presnosti modelu.\n",
    "- class_weight: Váhy tried.\n",
    "- max_samples: Maximálny počet vzoriek použitých na trénovanie každého stromu.\n",
    "-  n_jobs: Počet jadier procesora použitých na trénovanie.\n",
    "-  oob_score: Použiť out-of-bag vzorky na odhad presnosti. Out-of-bag vzorky sú vzorky, ktoré neboli použité na trénovanie stromu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Random Forest Parameters\n",
    "rf_parameters = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 6],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "scoring = ['accuracy', 'precision_micro']\n",
    "\n",
    "rf_clf = GridSearchCV(\n",
    "    estimator=estimator, \n",
    "    param_grid=rf_parameters, \n",
    "    scoring=scoring,\n",
    "    refit='accuracy', \n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_search = rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(rf_search.best_estimator_)\n",
    "print(rf_search.best_score_)\n",
    "print(rf_search.best_params_)\n",
    "print(rf_search.n_splits_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest before hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rf_search.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) je známy svojou jednoduchosťou a intuitívnosťou, čo uľahčuje jeho pochopenie a implementáciu. Jeho flexibilita výberu počtu susedov a metrík vzdialenosti umožňuje prispôsobiť model špecifickým potrebám dát. Navyše, KNN je efektívny pri zachytávaní komplexných vzorov v dátach, čo je výhodné, keď sú presné predpovede založené na podobnosti dát kľúčové."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vysvetlenie hyperparametrov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = KNeighborsClassifier().get_params()\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- algorithm: Algoritmus použitý na nájdenie najbližších susedov. Algoritmus môže byť \"ball_tree\", \"kd_tree\", \"brute\" alebo \"auto\".\n",
    "- leaf_size: Veľkosť listového uzla.\n",
    "- metric: Metrika použitá na výpočet vzdialenosti medzi bodmi. Metrika môže byť \"euclidean\", \"manhattan\" alebo \"minkowski\".\n",
    "- n_neighbors: Počet najbližších susedov.\n",
    "- p: Parameter pre metriku \"minkowski\".\n",
    "- weights: Váhy použité na predikciu bodu. Váhy môžu byť \"uniform\" alebo \"distance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "# KNN Parameters\n",
    "knn_parameters = {\n",
    "    'n_neighbors': [ 5, 10, 15, 20,25,30],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [20, 30, 40, 50],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'n_jobs': [-1, None],\n",
    "    'p': [1, 2]\n",
    "    \n",
    "}\n",
    "\n",
    "scoring = ['accuracy', 'precision_micro']\n",
    "\n",
    "knn_clf = GridSearchCV(\n",
    "    estimator=estimator, \n",
    "    param_grid=knn_parameters, \n",
    "    scoring=scoring,\n",
    "    refit='accuracy', \n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_search = knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print(knn_search.best_estimator_)\n",
    "print(knn_search.best_score_)\n",
    "print(knn_search.best_params_)\n",
    "print(knn_search.n_splits_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train_filtered, y_train)\n",
    "\n",
    "knn_y_pred = knn_model.predict(X_test_filtered)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "knn_precision = precision_score(y_test, knn_y_pred)\n",
    "knn_recall = recall_score(y_test, knn_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {knn_accuracy:.5f}\")\n",
    "print(f\"Precision: {knn_precision:.5f}\")\n",
    "print(f\"Recall: {knn_recall:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = knn_search.best_estimator_\n",
    "\n",
    "knn_model.fit(X_train_filtered, y_train)\n",
    "\n",
    "knn_y_pred = knn_model.predict(X_test_filtered)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "knn_precision = precision_score(y_test, knn_y_pred)\n",
    "knn_recall = recall_score(y_test, knn_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {knn_accuracy:.5f}\")\n",
    "print(f\"Precision: {knn_precision:.5f}\")\n",
    "print(f\"Recall: {knn_recall:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create individual models with their best parameters\n",
    "model1 = GradientBoostingClassifier(gb_search.best_params_)\n",
    "model2 = RandomForestClassifier(rf_search.best_params_)\n",
    "model3 = KNeighborsClassifier(knn_search.best_params_)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('gb', model1), ('rf', model2), ('knn', model3)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Fit the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "voting_score = voting_clf.score(X_test, y_test)\n",
    "print(f\"Voting Classifier Score: {voting_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create individual models with their best parameters\n",
    "model1 = GradientBoostingClassifier(gb_search.best_params_)\n",
    "model2 = RandomForestClassifier(rf_search.best_params_)\n",
    "model3 = KNeighborsClassifier(knn_search.best_params_)\n",
    "\n",
    "# Define the stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('gb', model1), ('rf', model2), ('knn', model3)],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "stacking_score = stacking_clf.score(X_test, y_test)\n",
    "print(f\"Stacking Classifier Score: {stacking_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Použitá literatúra:\n",
    "- https://github.com/thismlguy/analytics_vidhya/tree/master/Articles/Parameter_Tuning_GBM_with_Example\n",
    "- https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
